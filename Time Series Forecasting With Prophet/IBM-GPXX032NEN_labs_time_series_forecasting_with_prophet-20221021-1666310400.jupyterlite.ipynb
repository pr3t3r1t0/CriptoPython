{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Library Prophet makes forecasting with time series a lot easier. Before the introduction of libraries like  Scikit-learn, coding a machine learning pipeline was quite tricky; now, all it takes is a few lines of code. Prophet kind of does for time series what Scikit-learn did for machine learning. We say almost because time seris analysis is usually more complicated than Machine learning, and Prophet makes your job a lot easyer \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this Guided Project, we will go through one of the time series forecasting models, Prophet. We shall comprehend what prophet is and its benefits.\n",
        " - We'll go over two case studies.\n",
        " 1. Time series analysis of power consumption in India(2019-20) \n",
        "     - In this use case we are analyzing the usage consumption data that is available for the years 2019 and 2020, and we will be predicting        usage consumption for the years 2021 and 2022.\n",
        " 2. Time series analysis of Appliances count(2016)\n",
        "     - In this use case we are analyzing the Appliances which are used in January 2016 to May 2016, and we will be predicting appliances\n",
        "         for next five months which are June to Sept 2016.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Table of Contents**\n",
        "\n",
        "<ol>\n",
        "    <li><a href=\"https://#Time-series-Analysis\">Time series Analysis</a></li>\n",
        "    <li><a href=\"https://#Intoduction-to-Prophet\">Introduction to Prophet</a></li>\n",
        "     <li><a href=\"https://#benifits\">Benifits of Prophet</a></li>\n",
        "    <li><a href=\"https://#Setup\">Setup</a></li>\n",
        "    <ol><li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
        "    <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li></ol>  \n",
        "    <li><a href=\"https://#case-study\">Case Study</a></li>\n",
        "    <ol>\n",
        "        <li><a href=\"https://#Case-Study-1\">Time series analysis of power consumption in different states of India(2019-20)  </a>\n",
        "     <li><a href=\"https://#Case-Study-2\">Time series analysis of Appliances count(2016)</a>\n",
        "    </ol>\n",
        "    <li><a href=\"https://#Conclusion\">Conclusion</a>\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time Series Analysis:\n",
        "\n",
        " - Time series data is a collection of observations of measurements gathered over regular or irregular intervals of time.\n",
        " - Time series data have a natural temporal ordering\n",
        " - E.g. Sales data for a specific product at different times of the year.\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/time_series_img.jpg\" width=\"700\" height=\"400\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Introduction to Prophet\n",
        " - Prophet is a Python library that is open source and was created by Facebook primarily for time series forecasting.\n",
        " - It has the capability of automatically determining the right hyperparameters for the model.\n",
        " - It promotes insightful seasonal patterns.\n",
        " - It can fit time-series data having non-linearity in trends as well as holiday effects.\n",
        " - It has R and Python APIs for time-series forecasting\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2018/05/tumblr_inline_omh3tnv5zk1r1x9ql_500.png\" width=\"700\" height=\"400\"></center> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Benefits of using prophet\n",
        "1. It's automatic as well as quick. For manual time series analysis and decomposition, it saves time.\n",
        "2. It generates reliable and precise models.\n",
        "3. It can deal with outliers and missing values.\n",
        "4. It can manage the effects of seasonality and holidays.\n",
        "5. It produces a tunable model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Structure of Prophet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/prophet_structure-ImResizer.jpg\" width=\"700\" height=\"250\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prophet is particularly good at modeling time series that have multiple seasonalities and doesn’t face the drawbacks of other algorithms. At its core is the sum of three functions of time plus an error term: \n",
        "1) growth g(t)\n",
        "2) seasonality s(t)\n",
        "3) holidays h(t) , and error e_t :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/formula_prophet.png\" width=\"500\" height=\"350\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An Additive Model above can absorb the absence of seasonal effects by having s(t) = 0, as the other terms of the equation have no impact to predict future values in y(t). Unlike, fixed and linear regression models like Fama.\n",
        "Prophet is a modular and non — linear regression model that separates and recombines a single dataset of history. \n",
        "Feature Engineering when features explain a future value or when factors drive a forecast are removed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this lab, we will be using the following libraries:\n",
        "\n",
        "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
        "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
        "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
        "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
        "*   [`Plotly`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installing Required Libraries\n",
        "\n",
        "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
        "# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
        "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following required libraries are **not** pre-installed in the Skills Network Labs environment. **You will need to run the following cell** to install them:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After running below command Restart the kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nbformat\n",
            "  Obtaining dependency information for nbformat from https://files.pythonhosted.org/packages/f4/e7/ef30a90b70eba39e675689b9eaaa92530a71d7435ab8f9cae520814e0caf/nbformat-5.9.2-py3-none-any.whl.metadata\n",
            "  Downloading nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastjsonschema (from nbformat)\n",
            "  Obtaining dependency information for fastjsonschema from https://files.pythonhosted.org/packages/9d/93/a3ca3cdeb84065d7d8f8df4cb09ab44405f109183c1d2b915ec17574e6b1/fastjsonschema-2.18.0-py3-none-any.whl.metadata\n",
            "  Downloading fastjsonschema-2.18.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting jsonschema>=2.6 (from nbformat)\n",
            "  Obtaining dependency information for jsonschema>=2.6 from https://files.pythonhosted.org/packages/2b/ff/af59fd34bc4d7ac3e6e0cd1f3c10317d329b6c1aee179e8b24ad9a79fbac/jsonschema-4.19.0-py3-none-any.whl.metadata\n",
            "  Downloading jsonschema-4.19.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nbformat) (5.3.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nbformat) (5.9.0)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
            "     ------ --------------------------------- 10.2/61.2 kB ? eta -:--:--\n",
            "     ------------------- ------------------ 30.7/61.2 kB 445.2 kB/s eta 0:00:01\n",
            "     -------------------------------------- 61.2/61.2 kB 652.8 kB/s eta 0:00:00\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
            "  Obtaining dependency information for jsonschema-specifications>=2023.03.6 from https://files.pythonhosted.org/packages/1c/24/83349ac2189cc2435e84da3f69ba3c97314d3c0622628e55171c6798ed80/jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata\n",
            "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
            "  Obtaining dependency information for referencing>=0.28.4 from https://files.pythonhosted.org/packages/be/8e/56d6f1e2d591f4d6cbcba446cac4a1b0dc4f584537e2071d9bcee8eeab6b/referencing-0.30.2-py3-none-any.whl.metadata\n",
            "  Downloading referencing-0.30.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
            "  Obtaining dependency information for rpds-py>=0.7.1 from https://files.pythonhosted.org/packages/f2/7a/3721b7295d7fcff1d0857cca843fd3c4e6dcbab649edab514ded7e27660b/rpds_py-0.10.2-cp311-none-win_amd64.whl.metadata\n",
            "  Downloading rpds_py-0.10.2-cp311-none-win_amd64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jupyter-core->nbformat) (3.9.1)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jupyter-core->nbformat) (306)\n",
            "Downloading nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
            "   ---------------------------------------- 0.0/77.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 77.6/77.6 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading jsonschema-4.19.0-py3-none-any.whl (83 kB)\n",
            "   ---------------------------------------- 0.0/83.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 83.4/83.4 kB 4.9 MB/s eta 0:00:00\n",
            "Downloading fastjsonschema-2.18.0-py3-none-any.whl (23 kB)\n",
            "Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
            "Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
            "Downloading rpds_py-0.10.2-cp311-none-win_amd64.whl (184 kB)\n",
            "   ---------------------------------------- 0.0/184.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 184.5/184.5 kB 3.7 MB/s eta 0:00:00\n",
            "Installing collected packages: fastjsonschema, rpds-py, attrs, referencing, jsonschema-specifications, jsonschema, nbformat\n",
            "Successfully installed attrs-23.1.0 fastjsonschema-2.18.0 jsonschema-4.19.0 jsonschema-specifications-2023.7.1 nbformat-5.9.2 referencing-0.30.2 rpds-py-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade nbformat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note : Restart the Kernel After updating nbformat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting prophet\n",
            "  Obtaining dependency information for prophet from https://files.pythonhosted.org/packages/88/d6/ebc199ba1fd99719c8680b3fb90663aa4888871364c69bbf9629148b9724/prophet-1.1.4-py3-none-win_amd64.whl.metadata\n",
            "  Downloading prophet-1.1.4-py3-none-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
            "  Downloading cmdstanpy-1.1.0-py3-none-any.whl (83 kB)\n",
            "     ---------------------------------------- 0.0/83.2 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/83.2 kB ? eta -:--:--\n",
            "     ---- ----------------------------------- 10.2/83.2 kB ? eta -:--:--\n",
            "     -------------- ----------------------- 30.7/83.2 kB 330.3 kB/s eta 0:00:01\n",
            "     ---------------------------- --------- 61.4/83.2 kB 469.7 kB/s eta 0:00:01\n",
            "     -------------------------------------- 83.2/83.2 kB 521.5 kB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (1.24.3)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (3.7.2)\n",
            "Requirement already satisfied: pandas>=1.0.4 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (2.0.3)\n",
            "Collecting LunarCalendar>=0.0.9 (from prophet)\n",
            "  Downloading LunarCalendar-0.0.9-py2.py3-none-any.whl (18 kB)\n",
            "Collecting convertdate>=2.1.2 (from prophet)\n",
            "  Downloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
            "     ---------------------------------------- 0.0/47.9 kB ? eta -:--:--\n",
            "     ---------------------------------------- 47.9/47.9 kB 2.4 MB/s eta 0:00:00\n",
            "Collecting holidays>=0.25 (from prophet)\n",
            "  Obtaining dependency information for holidays>=0.25 from https://files.pythonhosted.org/packages/e0/7e/9d3b9387ac87500ae215da875660d219f7734e0dbe9437898a7388f0855c/holidays-0.32-py3-none-any.whl.metadata\n",
            "  Downloading holidays-0.32-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prophet) (2.8.2)\n",
            "Collecting tqdm>=4.36.1 (from prophet)\n",
            "  Obtaining dependency information for tqdm>=4.36.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
            "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
            "Collecting importlib-resources (from prophet)\n",
            "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
            "  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pymeeus<=1,>=0.3.13 (from convertdate>=2.1.2->prophet)\n",
            "  Downloading PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
            "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
            "     - -------------------------------------- 0.2/5.8 MB 7.3 MB/s eta 0:00:01\n",
            "     --- ------------------------------------ 0.5/5.8 MB 6.4 MB/s eta 0:00:01\n",
            "     ------ --------------------------------- 1.0/5.8 MB 7.9 MB/s eta 0:00:01\n",
            "     ---------- ----------------------------- 1.5/5.8 MB 8.9 MB/s eta 0:00:01\n",
            "     ----------- ---------------------------- 1.6/5.8 MB 8.7 MB/s eta 0:00:01\n",
            "     ------------ --------------------------- 1.8/5.8 MB 6.8 MB/s eta 0:00:01\n",
            "     --------------------- ------------------ 3.1/5.8 MB 9.9 MB/s eta 0:00:01\n",
            "     ------------------------- -------------- 3.6/5.8 MB 10.1 MB/s eta 0:00:01\n",
            "     ----------------------------- ---------- 4.2/5.8 MB 10.3 MB/s eta 0:00:01\n",
            "     -------------------------------- ------- 4.7/5.8 MB 10.4 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 5.3/5.8 MB 10.5 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------  5.7/5.8 MB 10.8 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 5.8/5.8 MB 7.8 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting ephem>=3.7.5.3 (from LunarCalendar>=0.0.9->prophet)\n",
            "  Downloading ephem-4.1.4-cp311-cp311-win_amd64.whl (1.4 MB)\n",
            "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
            "     ---------------- ----------------------- 0.6/1.4 MB 18.5 MB/s eta 0:00:01\n",
            "     ------------------------------- -------- 1.1/1.4 MB 14.2 MB/s eta 0:00:01\n",
            "     ---------------------------------------  1.4/1.4 MB 12.9 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.4/1.4 MB 8.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pytz in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from LunarCalendar>=0.0.9->prophet) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.0->prophet) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vivobook\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
            "Downloading prophet-1.1.4-py3-none-win_amd64.whl (12.9 MB)\n",
            "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.6/12.9 MB 13.1 MB/s eta 0:00:01\n",
            "   --- ------------------------------------ 1.0/12.9 MB 11.0 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 1.3/12.9 MB 9.2 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 1.7/12.9 MB 9.9 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 2.4/12.9 MB 10.1 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 2.9/12.9 MB 10.3 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 3.5/12.9 MB 10.5 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 4.0/12.9 MB 10.6 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 4.5/12.9 MB 10.7 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 5.1/12.9 MB 10.8 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 5.2/12.9 MB 10.8 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 5.2/12.9 MB 10.8 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 5.2/12.9 MB 10.8 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 5.7/12.9 MB 8.8 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 6.2/12.9 MB 9.0 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 6.6/12.9 MB 9.0 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 7.2/12.9 MB 9.2 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 7.7/12.9 MB 9.3 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 8.2/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.4/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.4/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.4/12.9 MB 9.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 8.4/12.9 MB 7.9 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 8.9/12.9 MB 8.0 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 9.5/12.9 MB 8.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 10.0/12.9 MB 8.3 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 10.5/12.9 MB 8.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 11.1/12.9 MB 8.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 11.6/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 12.1/12.9 MB 8.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.7/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  12.9/12.9 MB 8.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.9/12.9 MB 6.1 MB/s eta 0:00:00\n",
            "Downloading holidays-0.32-py3-none-any.whl (754 kB)\n",
            "   ---------------------------------------- 0.0/754.4 kB ? eta -:--:--\n",
            "   ----------------------------- --------- 573.4/754.4 kB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  747.5/754.4 kB 15.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  747.5/754.4 kB 15.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 754.4/754.4 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
            "Downloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: pymeeus\n",
            "  Building wheel for pymeeus (setup.py): started\n",
            "  Building wheel for pymeeus (setup.py): finished with status 'done'\n",
            "  Created wheel for pymeeus: filename=PyMeeus-0.5.12-py3-none-any.whl size=732053 sha256=2374959a98e076de53207d83dec48ff12e70fb90845977725452d340faf9afa3\n",
            "  Stored in directory: c:\\users\\vivobook\\appdata\\local\\pip\\cache\\wheels\\8f\\bd\\f9\\5c4c39b529e0322b08979e1c465e203218bc2cca75d20f7df5\n",
            "Successfully built pymeeus\n",
            "Installing collected packages: pymeeus, ephem, tqdm, importlib-resources, convertdate, LunarCalendar, holidays, cmdstanpy, prophet\n",
            "Successfully installed LunarCalendar-0.0.9 cmdstanpy-1.1.0 convertdate-2.4.0 ephem-4.1.4 holidays-0.32 importlib-resources-6.0.1 prophet-1.1.4 pymeeus-0.5.12 tqdm-4.66.1\n"
          ]
        }
      ],
      "source": [
        "!pip install prophet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About Dataset\n",
        "## Context\n",
        "India is the world's third-largest producer and third-largest consumer of electricity. The national electric grid in India has an installed capacity of 370.106 GW as of 31 March 2020. Renewable power plants, which also include large hydroelectric plants, constitute 35.86% of India's total installed capacity. During the 2018-19 fiscal year, the gross electricity generated by utilities in India was 1,372 TWh and the total electricity generation (utilities and non-utilities) in the country was 1,547 TWh. The gross electricity consumption in 2018-19 was 1,181 kWh per capita. \n",
        "In 2015-16, electric energy consumption in agriculture was recorded as being the highest (17.89%) worldwide. The per capita electricity consumption is low compared to most other countries despite India having a low electricity tariff.\n",
        "\n",
        "In light of the recent COVID-19 situation, when everyone has been under lockdown for the months of April & May the impacts of the lockdown on economic activities have been faced by every sector in a positive or a negative way. \n",
        "With the electricity consumption being so crucial to the country, we came up with a plan to study the impact on energy consumption state and region wise.\n",
        "\n",
        "The dataset is exhaustive in its demonstration of energy consumption state wise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Content\n",
        "Data is in the form of a time series for a period of 17 months beginning from 2nd Jan 2019 till 23rd May 2020.\n",
        "\n",
        "    Rows are indexed with dates and columns represent states.\n",
        "    Rows and columns put together, each datapoint reflects the power consumed in Mega Units (MU) by the given state (column) at the given date (row).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Kaggle Source - [https://www.kaggle.com/datasets/twinkle0705/state-wise-power-consumption-in-india)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Required Libraries\n",
        "\n",
        "*We recommend you import all required libraries in one place (here):*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CASE STUDY 1 - Time series analysis of power consumption in India(2019-20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read CSV file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read a comma-separated values (csv) file into DataFrame.\n",
        "\n",
        "<code>Parameters</code>\n",
        "filepath_or_bufferstr, path object or file-like object Any valid string path is acceptable. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/data/long_data_.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print the dataset information\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```DataFrame_Name.head``` function returns the first n rows for the object based on position. \n",
        "\n",
        " It is useful for quickly testing if your object has the right type of data in it.\n",
        "\n",
        " For negative values of n, this function returns all rows except the last |n| rows, equivalent to df[:n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>States</th>\n",
              "      <th>Regions</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>Dates</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Punjab</td>\n",
              "      <td>NR</td>\n",
              "      <td>31.519974</td>\n",
              "      <td>75.980003</td>\n",
              "      <td>02/01/2019 00:00:00</td>\n",
              "      <td>119.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Haryana</td>\n",
              "      <td>NR</td>\n",
              "      <td>28.450006</td>\n",
              "      <td>77.019991</td>\n",
              "      <td>02/01/2019 00:00:00</td>\n",
              "      <td>130.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rajasthan</td>\n",
              "      <td>NR</td>\n",
              "      <td>26.449999</td>\n",
              "      <td>74.639981</td>\n",
              "      <td>02/01/2019 00:00:00</td>\n",
              "      <td>234.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Delhi</td>\n",
              "      <td>NR</td>\n",
              "      <td>28.669993</td>\n",
              "      <td>77.230004</td>\n",
              "      <td>02/01/2019 00:00:00</td>\n",
              "      <td>85.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>UP</td>\n",
              "      <td>NR</td>\n",
              "      <td>27.599981</td>\n",
              "      <td>78.050006</td>\n",
              "      <td>02/01/2019 00:00:00</td>\n",
              "      <td>313.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      States Regions   latitude  longitude                Dates  Usage\n",
              "0     Punjab      NR  31.519974  75.980003  02/01/2019 00:00:00  119.9\n",
              "1    Haryana      NR  28.450006  77.019991  02/01/2019 00:00:00  130.3\n",
              "2  Rajasthan      NR  26.449999  74.639981  02/01/2019 00:00:00  234.1\n",
              "3      Delhi      NR  28.669993  77.230004  02/01/2019 00:00:00   85.8\n",
              "4         UP      NR  27.599981  78.050006  02/01/2019 00:00:00  313.9"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "```DataFrame_Name.shape``` gives us the ```dimension``` of the dataset (columns, rows) therefor, we have six timer series (rows) of length 16599 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16599, 6)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check All column Datatypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```dtypes``` function returns a Series with the data type of each column. \n",
        "\n",
        "The result’s index is the original DataFrame’s columns. Columns with mixed types are stored with the object dtype.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "States        object\n",
              "Regions       object\n",
              "latitude     float64\n",
              "longitude    float64\n",
              "Dates         object\n",
              "Usage        float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Format Dates column into datetime type\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A ```to_datetime``` function converts a scalar, array-like, Series or DataFrame/dict-like to a pandas datetime object.\n",
        "\n",
        "Here we have convert ```Dates``` column to ```datetime``` object as it was in ```object``` type and for prophet model we need datetime type.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "time data \"13/01/2019 00:00:00\" doesn't match format \"%m/%d/%Y %H:%M:%S\", at position 11. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32md:\\Codigos\\Python\\CriptoPython\\Time Series Forecasting With Prophet\\IBM-GPXX032NEN_labs_time_series_forecasting_with_prophet-20221021-1666310400.jupyterlite.ipynb Cell 44\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Codigos/Python/CriptoPython/Time%20Series%20Forecasting%20With%20Prophet/IBM-GPXX032NEN_labs_time_series_forecasting_with_prophet-20221021-1666310400.jupyterlite.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mDates\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mDates\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:1046\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1044\u001b[0m             result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mtz_localize(\u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1045\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1046\u001b[0m     cache_array \u001b[39m=\u001b[39m _maybe_cache(arg, \u001b[39mformat\u001b[39;49m, cache, convert_listlike)\n\u001b[0;32m   1047\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cache_array\u001b[39m.\u001b[39mempty:\n\u001b[0;32m   1048\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:250\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    248\u001b[0m unique_dates \u001b[39m=\u001b[39m unique(arg)\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_dates) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(arg):\n\u001b[1;32m--> 250\u001b[0m     cache_dates \u001b[39m=\u001b[39m convert_listlike(unique_dates, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m    251\u001b[0m     \u001b[39m# GH#45319\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39;49m, exact, errors)\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[39m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    474\u001b[0m     arg,\n\u001b[0;32m    475\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     errors: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    480\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[0;32m    481\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors, utc\u001b[39m=\u001b[39;49mutc)\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m tz \u001b[39min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m         \u001b[39mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: time data \"13/01/2019 00:00:00\" doesn't match format \"%m/%d/%Y %H:%M:%S\", at position 11. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
          ]
        }
      ],
      "source": [
        "df['Dates'] = pd.to_datetime(df['Dates'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Group by Dates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A ```groupby``` operation involves some combination of splitting the object, applying a function, and combining the results. \n",
        "\n",
        "\n",
        "Here we  ```groupby``` our dataframe using the ```Dates``` column. This is because we have different states of data so we will find average usage for all the states.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.groupby('Dates',as_index=False).mean()\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset shape is 498 because we have approx 1 year 5 months of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### select the datetime column and target column\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here We are selecting only 2 columns which are needed for time series forecasting as prophet model needs dataframe with 2 columns\n",
        "\n",
        "1) Datetime column (Dates)\n",
        "\n",
        "2) Target column (Usage)\n",
        "\n",
        "To ```select multiple columns```, use a ``list`` of ``column names`` within the selection brackets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df[['Dates','Usage']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also use drop function to drop unnecessary column by using, drop specifying  labels from rows or columns.\n",
        "\n",
        "Axis=0 can be used for dropping particular Rows.\n",
        "\n",
        "Axis=1 can be used for dropping particular Columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##optional if you are using above command\n",
        "##df.drop(['latitude','longitude'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Plotly library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/Untitled%20design%20%289%29.png\" width=\"550\" height=\"550\"></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You’ve probably heard about ```Matplotib and Seaborn``` since they are often mentioned in Data Science courses. \n",
        "But do you know these libraries are designed for ```basic plotting```.\n",
        "Therefore here we have used ```Plotly``` library to plot our time series data.\n",
        "\n",
        "The ```plotly``` Python library is an ```interactive, open-source``` plotting library that supports over 40 unique chart types covering a wide range of statistical, financial, geographic, scientific, and 3-dimensional use-cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can simply install plotly using below command.\n",
        "\n",
        "```pip install plotly```\n",
        "\n",
        "### Features of Plotly:\n",
        "1) zoom\n",
        "2) pan \n",
        "3) hover over datapoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "```X cordinates``` will represent ```Dates``` column from dataframe (df).\n",
        "\n",
        "```Y cordinates``` will represent target column which is ```Usage``` column from dataframe (df).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(df, x='Dates', y='Usage')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare for Prophet  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For prophet to work, we need to change the names of these columns to 'ds' and 'y'.\n",
        "\n",
        "We will convert datetime column to ds and target column to y.\n",
        "\n",
        "ds - datestamp column\n",
        "\n",
        "y - target column\n",
        "\n",
        "DataFrame.columns attribute return the column labels of the given Dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = ['ds','y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print 5 rows of the Dataframe \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can see columns names are changed to ```ds``` and ```y```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fit the model by ```instantiating a new Prophet object```. Any settings to the forecasting procedure are passed into the constructor. \n",
        "\n",
        "Then you call the fit method and pass in the historical dataframe. \n",
        "\n",
        "Fitting should take 1-7 seconds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=Prophet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit the model to dataframe (df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ```fit()``` function takes a DataFrame of time series data. The DataFrame must have a specific format. \n",
        "\n",
        "The first column must have the name ```ds``` and contain the date-times. \n",
        "\n",
        "The second column must have the name ```y``` and contain the observations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print Model Components\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to see the forecast components, you can use the Prophet.plot_components method. \n",
        "\n",
        "By default you’ll see the trend, yearly seasonality, and weekly seasonality of the time series. If you include holidays, you’ll see those here, too.\n",
        "\n",
        "In this time series, the seasonality is not a constant additive factor as assumed by Prophet, rather it grows with the trend. This is multiplicative seasonality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.component_modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make Future Dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A ```make_future_dataframe``` function Make dataframe with future dates for forecasting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Arguments:\n",
        "<table height=\"40%\",width=\"60%\" style=\"font-size:16px;\">\n",
        "    \n",
        "<tr><td>periods</td><td> - </td> <td>Int number of periods to forecast forward.</td></tr>\n",
        "\n",
        "<tr><td>freq</td><td> - </td> <td>'day', 'week', 'month', 'quarter', 'year', 1(1 sec), 60(1 minute) or 3600(1 hour).</td></tr>\n",
        "\n",
        "<tr><td>include_history</td><td> - </td> <td>Boolean to include the historical dates in the data frame for predictions.</td></tr>\n",
        "   \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_dates = model.make_future_dataframe(periods=365,freq='d',include_history=True)\n",
        "future_dates.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the future_dates datframe first 5 rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_dates.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction of the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To predict, we use the predict() method and pass in the future dataframe as shown below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction=model.predict(future_dates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### From the results generated, the model has generated a lot of information in addition to the predicted ds and yhat column. \n",
        "#### The most important column is the ```yhat column```, as it is what represents your ```Usage forecast```.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "yhat upper values and yhate lower values - Uncertainity Interval\n",
        "\n",
        "There are three sources of uncertainty in the forecast:\n",
        " 1) uncertainty in the trend. \n",
        " 2) uncertainty in the seasonality estimates.\n",
        " 3) additional observation noise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot The Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ```scatter trace``` type encompasses ```line charts, scatter charts, text charts, and bubble charts.```\n",
        "\n",
        "The data visualized as scatter point or lines is set in x and y. Text (appearing either on the chart or on hover only) is via text.\n",
        "\n",
        "Parameteres:\n",
        "- x – Sets the x coordinates.\n",
        "- y – Sets the y coordinates.\n",
        "- mode – Determines the drawing mode for this scatter trace. \n",
        "  If there are less than 20 points and the trace is not stacked then the default is “lines+markers”. Otherwise, “lines”.\n",
        "- name - Sets the trace name. The trace name appear as the legend item and on hover.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trace_open = go.Scatter(\n",
        "    x = prediction[\"ds\"],\n",
        "    y = prediction[\"yhat\"],\n",
        "    mode = 'lines',\n",
        "    name=\"Forecast\"\n",
        ")\n",
        "trace_high = go.Scatter(\n",
        "    x = prediction[\"ds\"],\n",
        "    y = prediction[\"yhat_upper\"],\n",
        "    mode = 'lines',\n",
        "    fill = \"tonexty\", \n",
        "    line = {\"color\": \"#57b8ff\"}, \n",
        "    name=\"Higher uncertainty interval\"\n",
        ")\n",
        "trace_low = go.Scatter(\n",
        "    x = prediction[\"ds\"],\n",
        "    y = prediction[\"yhat_lower\"],\n",
        "    mode = 'lines',\n",
        "    fill = \"tonexty\", \n",
        "    line = {\"color\": \"#57b8ff\"}, \n",
        "    name=\"Lower uncertainty interval\"\n",
        ")\n",
        "trace_close = go.Scatter(\n",
        "    x = df[\"ds\"],\n",
        "    y = df[\"y\"],\n",
        "    name=\"Data values\"\n",
        ")\n",
        "\n",
        "#make list for all three scattle objects.\n",
        "data = [trace_open,trace_high,trace_low,trace_close]\n",
        "# Construct a new Layout object. \n",
        "#title - It will display string as a title of graph\n",
        "layout = go.Layout(title=\"Power consumption forecasting\")\n",
        "#A list or tuple of trace instances (e.g. [Scatter(…), Bar(…)]) or A single trace instance (e.g. Scatter(…), Bar(…), etc.)\n",
        "#A list or tuple of dicts of string/value properties where: - The ‘type’ property specifies the trace type.\n",
        "\n",
        "fig = go.Figure(data=data)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the Actual v/s Predicted Without Optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig = go.Figure([go.Scatter(x=df['ds'], y=df['y'],mode='lines',\n",
        "                    name='Actual')])\n",
        "#You can add traces using an Express plot by using add_trace\n",
        "fig.add_trace(go.Scatter(x=prediction['ds'], y=prediction['yhat'],\n",
        "                   mode='lines+markers',\n",
        "                    name='predicted'))\n",
        "#To display a figure using the renderers framework, you call the .show() method on a graph object figure, or pass the figure to the plotly.io.show function. \n",
        "#With either approach, plotly.py will display the figure using the current default renderer(s).\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Absolute Error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now understand the MAE (Mean Absolute Error).\n",
        "Absolute error refers to the magnitude of difference between the prediction of an observation and the true value of that observation.\n",
        "It is thus an arithmetic average of the absolute errors $MAE=\\frac{1}{n}\\sum_{i=1}^{n}|x_i-y_i|$ where ``` y{i}``` is the prediction and ```x{i}``` the true value. Note that alternative formulations may include relative frequencies as weight factors. The mean absolute error uses the same scale as the data being measured. This is known as a scale-dependent accuracy measure and therefore cannot be used to make comparisons between series using different scales.\n",
        "\n",
        "### MAE Range is from 0 to ∞ (infinite). The lower the MAE, the better a model fits a dataset.\n",
        "\n",
        "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/MAE_img.png\" width=\"600\" height=\"500\"></center> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we are getting ```7.9``` MAE which is good but optimizing model can help to reduced Errors.\n",
        "\n",
        "In previous graph of predicted V/s Actual we can see that curves are not perfect for prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Return a Numpy representation of the DataFrame.\n",
        "y_true = df['y'].values\n",
        "\n",
        "#Here we have specified [:498] because in y_true we have 498 data points so for comparing both series we need equal shape of series.\n",
        "y_pred = prediction['yhat'][:498].values \n",
        "\n",
        "#Parameters:\n",
        "#y_truearray-like of shape = (n_samples) or (n_samples, n_outputs)\n",
        "#Ground truth (correct) target values.\n",
        "\n",
        "#y_predarray-like of shape = (n_samples) or (n_samples, n_outputs)\n",
        "#Estimated target values.\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print('MAE: %.3f' % mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimizing the model for better forecasting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table  style=' font-size: 16px;'>\n",
        "<tr><td>name  <td>String name of the seasonality component.</td></tr>\n",
        "<tr><td> period</td> <td> Float number of days in one period.</td></tr>\n",
        "<tr><td> fourier_order</td> <td> Int number of Fourier components to use.</td></tr>\n",
        "<tr><td> prior_scale</td> <td> Optional float prior scale for this component. </td></tr>\n",
        "<tr><td> mode</td> <td> Optional 'additive' or 'multiplicative'.</td></tr>\n",
        "<tr><td> condition_name </td> <td> String name of the seasonality condition.</td></tr>\n",
        "</table>\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prophet will by default fit weekly and yearly seasonalities, if the time series is more than two cycles long.\n",
        "\n",
        "It will also fit daily seasonality for a sub-daily time series. \n",
        "\n",
        "You can add other seasonalities (monthly, quarterly, hourly) using the add_seasonality method (Python)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Here we have taken period=365, as one year consist of 365 days and Fourier_order=70.\n",
        "#### In this case study, I have randomly found 70 is a good fit for my model. \n",
        "#### Fourier_order can differ for different datasets.\n",
        "#### Note : Higher Furier_order Value can lead to Overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1=Prophet(daily_seasonality=True).add_seasonality(name='yearly',period=365,fourier_order=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model with Hyper Patameter Tuning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ```fit()``` function takes a ```DataFrame``` of ```time series data```. \n",
        "\n",
        "The DataFrame must have a specific format.\n",
        "\n",
        "The ```first column``` must have the name ```'ds'``` and contain the ```date-times.``` .\n",
        "\n",
        "The ```second column``` must have the name ```'y'``` and contain the ```observations```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.fit(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print the components of model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.component_modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make future dataframe for next 1 year\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we are taking period = 365 beacause we have 365 days in a year.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_dates1=model1.make_future_dataframe(periods=365)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict the Datapoint for next year.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction1=model1.predict(future_dates1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### After optimization, we are getting the value of MAE as 5.6, which is better than above MAE i.e 7.9. Hence This model gives a good Prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "y_true = df['y'].values\n",
        "y_pred = prediction1['yhat'][:498].values\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print('MAE: %.3f' % mae)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot expected vs actual After Optimizng\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure([go.Scatter(x=df['ds'], y=df['y'],mode='lines',\n",
        "                    name='Actual')])\n",
        "\n",
        "fig.add_trace(go.Scatter(x=prediction1['ds'], y=prediction1['yhat'],\n",
        "                   mode='lines+markers',\n",
        "                    name='predicted'))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CASE STUDY 2 - Time series analysis of Appliances count (2016)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Kaggle Source - [https://www.kaggle.com/code/callherro/energy-data/data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#read CSV file\n",
        "df=pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX032NEN/images/data/energydata_complete.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#display dataframe\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Select date column and target column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "df=df[['date','Appliances']]\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Plot dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "df.plot()\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Rename column to ds and y\n",
        "    ds - datestamp column\n",
        "    y - target column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "df.columns = ['ds','y']\n",
        "df.head()\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Intialize model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "model=Prophet()\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Fit model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "model.fit(df)\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Print model components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "model.component_modes\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Create future dates of 150 days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "future_dates=model.make_future_dataframe(periods=150)\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Predict the target for next 150 days\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "prediction=model.predict(future_dates)\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Find MAE (Mean Absolute Error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#To do - Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<details><summary>Solution</summary>\n",
        "\n",
        "```python\n",
        "\n",
        "y_true = df['y'].values\n",
        "y_pred = prediction['yhat'][:19735].values\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print('MAE: %.3f' % mae)\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "Wow! With three small changes to the hyperparameters i.e name,period and fourier_order, we have a pretty accurate model of prophet. \n",
        "\n",
        "It quickly helps us to find insightful predictions on the time series analysis problem and also deal with outliers.\n",
        "\n",
        "From this casestudy we have also learn about plotly, Mean Absolute Error and Prophet's Hyper parameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Author\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Jigisha Barbhaya](https://www.linkedin.com/in/jigisha-barbhaya/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMGPXX032NEN123-2022-01-01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other Contibutors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright © 2022 IBM Corporation. All rights reserved.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
